{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "layout: post\n",
    "title: Computing Bias HW\n",
    "description: HW\n",
    "toc: false\n",
    "comments: false\n",
    "categories: [5.A, C4.1]\n",
    "courses: { compsci: {week: 16} }\n",
    "type: tangibles\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First question:\n",
    "\n",
    "Computer bias is defined as the unjust results that software or algorithms generate, either favorable or disadvantageous to particular groups. It may be accidental (faulty data or unbalanced training sets) or purposeful (embedded biases).\n",
    "\n",
    "An intended example of bias would be a recruiting algorithm that favors a particular demographic; inadvertent bias would be demonstrated by a facial recognition system that performs less accurately on darker skin tones because of skewed training data.\n",
    "\n",
    "Programmers can lessen bias by making sure their teams are diverse, abiding by moral principles, and keeping an eye on their algorithms once they are deployed.\n",
    "\n",
    "Second question:\n",
    "\n",
    "Different types of bias exist such as emergent bias results from skewed training data, and inherent bias which is deeply embedded in software and affected by society standards.\n",
    "\n",
    "Examples: Inherent bias in video games can result in stereotyped character designs that negatively affect diversity. Emerging bias in content suggestions on social media can change public perspective on different things."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
